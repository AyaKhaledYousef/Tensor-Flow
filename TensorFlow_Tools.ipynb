{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 421.8 MB 29 kB/s  eta 0:00:019  |▍                               | 5.3 MB 1.5 MB/s eta 0:04:42     |█                               | 12.0 MB 415 kB/s eta 0:16:27     |██▋                             | 34.2 MB 3.2 MB/s eta 0:02:03     |████▌                           | 58.8 MB 170 kB/s eta 0:35:23     |████▊                           | 62.6 MB 877 kB/s eta 0:06:50     |█████                           | 67.2 MB 1.6 MB/s eta 0:03:43     |█████▍                          | 71.6 MB 1.0 MB/s eta 0:05:39     |██████▉                         | 89.5 MB 1.0 MB/s eta 0:05:27     |███████▎                        | 96.4 MB 2.2 MB/s eta 0:02:29     |████████                        | 104.9 MB 2.7 MB/s eta 0:01:57     |████████▏                       | 108.1 MB 1.9 MB/s eta 0:02:48     |████████▋                       | 113.2 MB 857 kB/s eta 0:06:00     |█████████▍                      | 123.6 MB 1.7 MB/s eta 0:03:01     |█████████▋                      | 127.1 MB 1.3 MB/s eta 0:03:53     |██████████▏                     | 134.3 MB 1.3 MB/s eta 0:03:39     |███████████▎                    | 148.1 MB 2.6 MB/s eta 0:01:47     |███████████▊                    | 154.9 MB 4.4 MB/s eta 0:01:01     |█████████████▍                  | 177.0 MB 942 kB/s eta 0:04:20     |█████████████▊                  | 181.2 MB 1.1 MB/s eta 0:03:34     |█████████████▉                  | 182.0 MB 1.1 MB/s eta 0:03:34     |███████████████▏                | 200.3 MB 2.2 MB/s eta 0:01:42     |████████████████▍               | 216.7 MB 2.5 MB/s eta 0:01:24     |█████████████████               | 224.6 MB 1.2 MB/s eta 0:02:44     |█████████████████               | 224.8 MB 1.2 MB/s eta 0:02:44     |█████████████████████▉          | 288.5 MB 1.0 MB/s eta 0:02:09     |██████████████████████          | 290.5 MB 1.1 MB/s eta 0:01:56     |███████████████████████▋        | 311.1 MB 1.5 MB/s eta 0:01:13     |███████████████████████████     | 354.6 MB 1.8 MB/s eta 0:00:39     |█████████████████████████████▌  | 388.4 MB 2.4 MB/s eta 0:00:15     |█████████████████████████████▋  | 390.7 MB 2.3 MB/s eta 0:00:14     |██████████████████████████████▎ | 398.5 MB 2.4 MB/s eta 0:00:10\n",
      "\u001b[?25hCollecting google-pasta>=0.1.6\n",
      "  Downloading google_pasta-0.1.8-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.0\n",
      "  Downloading Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[K     |████████████████████████████████| 41 kB 312 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.8.0\n",
      "  Downloading protobuf-3.11.2-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in ./Pictures/home/aya/pictures/lib/python3.7/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in ./Pictures/home/aya/pictures/lib/python3.7/site-packages (from tensorflow) (0.33.6)\n",
      "Collecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.26.0-cp37-cp37m-manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 810 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.1.0.tar.gz (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 1.3 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Downloading tensorboard-2.1.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in ./Pictures/home/aya/pictures/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Collecting scipy==1.4.1; python_version >= \"3\"\n",
      "  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.1 MB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in ./Pictures/home/aya/pictures/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 1.9 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting absl-py>=0.7.0\n",
      "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
      "\u001b[K     |████████████████████████████████| 104 kB 5.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in ./Pictures/home/aya/pictures/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow) (41.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./Pictures/home/aya/pictures/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.1.1-py2.py3-none-any.whl (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 2.2 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.11.0-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 2.4 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in ./Pictures/home/aya/pictures/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: h5py in ./Pictures/home/aya/pictures/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./Pictures/home/aya/pictures/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./Pictures/home/aya/pictures/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./Pictures/home/aya/pictures/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./Pictures/home/aya/pictures/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.9.11)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.0.0-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<4.1,>=3.1.4\n",
      "  Using cached rsa-4.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 2.3 MB/s eta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor, opt-einsum, gast, absl-py\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=c4042cf9bcac52c29ed183761ee6368db1e88a5c42baa6cd43d5968ae9dfd3a6\n",
      "  Stored in directory: /home/aya/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "  Building wheel for opt-einsum (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for opt-einsum: filename=opt_einsum-3.1.0-py3-none-any.whl size=61681 sha256=238717f3e24f830871f778eb1731c4a8db91f8eb99c6d6365a79fa9ba3c43b4f\n",
      "  Stored in directory: /home/aya/.cache/pip/wheels/21/e3/31/0d3919995e859eff01713d381aac3b6b43c69915a2942e5c65\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=39eeaa51a63fb6a301aeb0b4b17ee374aa61e4d5526edbde9067bd1430567f0f\n",
      "  Stored in directory: /home/aya/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121931 sha256=a4206d4ccc19050d63aa628b0f7da260cf257ca394000ccc3a90649b6b159f54\n",
      "  Stored in directory: /home/aya/.cache/pip/wheels/cc/af/1a/498a24d0730ef484019e007bb9e8cef3ac00311a672c049a3e\n",
      "Successfully built termcolor opt-einsum gast absl-py\n",
      "Installing collected packages: google-pasta, keras-preprocessing, protobuf, astor, grpcio, tensorflow-estimator, termcolor, opt-einsum, gast, absl-py, markdown, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, scipy, keras-applications, tensorflow\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.3.1\n",
      "    Uninstalling scipy-1.3.1:\n",
      "      Successfully uninstalled scipy-1.3.1\n",
      "Successfully installed absl-py-0.9.0 astor-0.8.1 cachetools-4.0.0 gast-0.2.2 google-auth-1.11.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.26.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 oauthlib-3.1.0 opt-einsum-3.1.0 protobuf-3.11.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.0 scipy-1.4.1 tensorboard-2.1.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0 termcolor-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-591c5ee42ea9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "#Last version :(\n",
    "sess =  tf.Session()\n",
    "b = tf.constant(5)\n",
    "print(sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant(8)\n",
    "with  tf.compat.v1.Session() as sess : \n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(3)\n",
    "b = tf.constant(3,tf.float32)\n",
    "c = tf.constant([2,5,6,9,6])\n",
    "d = tf.constant([[2,5,6],\n",
    "                 [8,5,8],\n",
    "                 [8,8,1]])\n",
    "e = tf.constant('I love TensorFlow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  3\n",
      "b =  3.0\n",
      "c =  [2 5 6 9 6]\n",
      "d = \n",
      " [[2 5 6]\n",
      " [8 5 8]\n",
      " [8 8 1]]\n",
      "e =  b'I love TensorFlow'\n"
     ]
    }
   ],
   "source": [
    "with  tf.compat.v1.Session() as sess :\n",
    "    print('a = ',sess.run(a))\n",
    "    print('b = ',sess.run(b))\n",
    "    print('c = ',sess.run(c))\n",
    "    print('d = \\n',sess.run(d))\n",
    "    print('e = ',sess.run(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_4:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aya/Pictures/home/aya/pictures/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(3)\n",
    "b = tf.Variable(3,tf.float32)\n",
    "c = tf.Variable([2,5,6,9,6])\n",
    "d = tf.Variable([[2,5,6],[8,5,8], [8,8,1]])\n",
    "e = tf.Variable('I love TensorFlow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  3\n",
      "b =  3\n",
      "c =  [2 5 6 9 6]\n",
      "d = \n",
      " [[2 5 6]\n",
      " [8 5 8]\n",
      " [8 8 1]]\n",
      "e =  b'I love TensorFlow'\n"
     ]
    }
   ],
   "source": [
    "with  tf.compat.v1.Session() as sess :\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    print('a = ',sess.run(a))\n",
    "    print('b = ',sess.run(b))\n",
    "    print('c = ',sess.run(c))\n",
    "    print('d = \\n',sess.run(d))\n",
    "    print('e = ',sess.run(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original price is :  20\n"
     ]
    }
   ],
   "source": [
    "price = tf.Variable(20) \n",
    "sess = tf.compat.v1.Session()\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print('original price is : ',sess.run(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the price is :  30\n",
      "the price is :  40\n",
      "the price is :  50\n",
      "the price is :  60\n"
     ]
    }
   ],
   "source": [
    "price = tf.Variable(30) \n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "print('the price is : ',sess.run(price))\n",
    "\n",
    "price = tf.Variable(40) \n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "print('the price is : ',sess.run(price))\n",
    "\n",
    "price = tf.Variable(50) \n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "print('the price is : ',sess.run(price))\n",
    "\n",
    "price = tf.Variable(60) \n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "print('the price is : ',sess.run(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new price is :  50\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "value = tf.assign(value,newvalue)\n",
    "'''\n",
    "price = tf.compat.v1.assign(price,50)\n",
    "print('new price is : ',sess.run(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new price is :  120\n",
      "new price is :  130\n",
      "new price is :  140\n",
      "new price is :  150\n",
      "new price is :  160\n",
      "new price is :  170\n",
      "new price is :  180\n",
      "new price is :  190\n",
      "new price is :  200\n",
      "new price is :  210\n"
     ]
    }
   ],
   "source": [
    "for j in range(10) : \n",
    "    price = tf.compat.v1.assign(price,price+10)\n",
    "    print('new price is : ',sess.run(price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.compat.v1.placeholder(tf.float32)\n",
    "with tf.compat.v1.Session() as sess : \n",
    "    result = sess.run(a , feed_dict ={a:3})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.compat.v1.placeholder(tf.float32)\n",
    "b = a*2\n",
    "with tf.compat.v1.Session() as sess : \n",
    "    result = sess.run(b , feed_dict ={a:3})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "770.5\n"
     ]
    }
   ],
   "source": [
    "x = tf.compat.v1.placeholder(tf.float32)\n",
    "y = tf.compat.v1.placeholder(tf.float32)\n",
    "z = tf.compat.v1.placeholder(tf.float32)\n",
    "w = tf.compat.v1.placeholder(tf.float32)\n",
    "\n",
    "b = x*2 + 3*y**4 - 4/z + w-9\n",
    "\n",
    "with tf.compat.v1.Session() as sess : \n",
    "    result = sess.run(b , feed_dict ={x:3,y:4,z:8,w:6})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.compat.v1.placeholder(tf.float32)\n",
    "y = x**2\n",
    "with tf.compat.v1.Session() as sess :\n",
    "    print(sess.run(y,feed_dict={x:5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  25.   64.  100. 2500.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.compat.v1.placeholder(tf.float32)\n",
    "y = x**2\n",
    "with tf.compat.v1.Session() as sess :\n",
    "    print(sess.run(y, {x:[5,8,10,50]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  25.   36.   49.   64.   81.  100.  121.  144.  169.  196.  225.  256.\n",
      "  289.  324.  361.  400.  441.  484.  529.  576.  625.  676.  729.  784.\n",
      "  841.  900.  961. 1024. 1089. 1156. 1225. 1296. 1369. 1444. 1521. 1600.\n",
      " 1681. 1764. 1849. 1936. 2025. 2116. 2209. 2304. 2401. 2500. 2601. 2704.\n",
      " 2809. 2916. 3025. 3136. 3249. 3364. 3481. 3600. 3721. 3844. 3969. 4096.\n",
      " 4225. 4356. 4489. 4624. 4761. 4900. 5041. 5184. 5329. 5476. 5625. 5776.\n",
      " 5929. 6084. 6241. 6400. 6561. 6724. 6889. 7056. 7225. 7396. 7569. 7744.\n",
      " 7921. 8100. 8281. 8464. 8649. 8836. 9025. 9216. 9409. 9604. 9801.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.compat.v1.placeholder(tf.float32)\n",
    "y = x**2\n",
    "with tf.compat.v1.Session() as sess :\n",
    "        print(sess.run(y, {x:list(range(5,100))}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aya/Pictures/home/aya/pictures/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "[22. 32. 42. 52.]\n"
     ]
    }
   ],
   "source": [
    "w = tf.compat.v1.constant([5.0])\n",
    "b = tf.compat.v1.Variable([7.0],tf.float32)\n",
    "\n",
    "x = tf.compat.v1.placeholder(tf.float32)\n",
    "\n",
    "LinearRegressionModel = w*x + b\n",
    "\n",
    "with tf.compat.v1.Session() as sess :\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    print(sess.run(LinearRegressionModel,{x:[3,5,7,9]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hi people '\n"
     ]
    }
   ],
   "source": [
    "s1 = tf.constant('hi ')\n",
    "s2 = tf.constant('people ')\n",
    "s3 = tf.add(s1,s2)\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "print(sess.run(s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "s1 = tf.constant(20)\n",
    "s2 = tf.constant(30)\n",
    "s3 = tf.add(s1,s2)\n",
    "sess = tf.compat.v1.Session()\n",
    "print(sess.run(s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "s1 = tf.constant(20)\n",
    "s2 = tf.constant(30)\n",
    "s3 = tf.multiply(s1,s2)\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "print(sess.run(s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10\n"
     ]
    }
   ],
   "source": [
    "s1 = tf.constant(20)\n",
    "s2 = tf.constant(30)\n",
    "s3 = tf.subtract(s1,s2)\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "print(sess.run(s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "s1 = tf.constant(20)\n",
    "s2 = tf.constant(30)\n",
    "s3 = tf.divide(s1,s2)\n",
    "sess = tf.compat.v1.Session()\n",
    "print(sess.run(s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "s1 = tf.constant(20)\n",
    "s2 = tf.constant(3)\n",
    "s3 = tf.pow(s1,s2)\n",
    "sess = tf.compat.v1.Session()\n",
    "print(sess.run(s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  8 10 12]\n"
     ]
    }
   ],
   "source": [
    "s1 = tf.constant([5,6,7,8])\n",
    "s2 = tf.constant(30)\n",
    "s3 = tf.add(s1,s2)\n",
    "sess = tf.compat.v1.Session()\n",
    "print(sess.run(s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  8 10 12]\n"
     ]
    }
   ],
   "source": [
    "s1 = tf.constant([5,6,7,8])\n",
    "s2 = tf.constant([1,2,3,4])\n",
    "s3 = tf.add(s1,s2)\n",
    "sess = tf.compat.v1.Session()\n",
    "print(sess.run(s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 4 and 9 for 'Add_5' (op: 'Add') with input shapes: [4], [9].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/Pictures/home/aya/pictures/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1618\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1619\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1620\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 4 and 9 for 'Add_5' (op: 'Add') with input shapes: [4], [9].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ccf0f5dd3e76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ms3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Pictures/home/aya/pictures/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m--> 347\u001b[0;31m         \"Add\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m    348\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     result = _dispatch.dispatch(\n",
      "\u001b[0;32m~/Pictures/home/aya/pictures/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    740\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    741\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Pictures/home/aya/pictures/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3320\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3321\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3322\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3323\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3324\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Pictures/home/aya/pictures/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1784\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1785\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1786\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1787\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Pictures/home/aya/pictures/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1620\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1622\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 4 and 9 for 'Add_5' (op: 'Add') with input shapes: [4], [9]."
     ]
    }
   ],
   "source": [
    "s1 = tf.constant([5,6,7,8])\n",
    "s2 = tf.constant([1,2,3,4,8,9,7,8,9])\n",
    "s3 = tf.add(s1,s2)\n",
    "sess = tf.compat.v1.Session()\n",
    "print(sess.run(s3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16.]]\n"
     ]
    }
   ],
   "source": [
    "matrix1 = tf.constant([[5., 3.]])\n",
    "matrix2 = tf.constant([[2.],\n",
    "                       [2.]])\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    result = sess.run(product)\n",
    "    print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 1 7 1]\n",
      " [6 2 9 2]\n",
      " [9 8 5 3]\n",
      " [8 9 6 9]]\n"
     ]
    }
   ],
   "source": [
    "matrix1 = tf.constant([[5,6,9,8],\n",
    "                      [1,2,8,9],\n",
    "                      [7,9,5,6],\n",
    "                      [1,2,3,9]])\n",
    "matrix2 = tf.compat.v1.matrix_transpose(matrix1)\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    result = sess.run(matrix2)\n",
    "    print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6- Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "#sess = tf.compat.v1.Session()\n",
    "graph = tf.compat.v1.get_default_graph()\n",
    "graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'Const' type=Const>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= tf.constant(5)\n",
    "graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'Const' type=Const>, <tf.Operation 'Const_1' type=Const>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b= tf.constant(7)\n",
    "graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'Const_1' type=Const>,\n",
       " <tf.Operation 'Add' type=Add>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c= tf.add(a,b)\n",
    "graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'Const_1' type=Const>,\n",
       " <tf.Operation 'Add' type=Add>,\n",
       " <tf.Operation 'Placeholder' type=Placeholder>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d= tf.compat.v1.placeholder(tf.float32)\n",
    "graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aya/Pictures/home/aya/pictures/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'Const_1' type=Const>,\n",
       " <tf.Operation 'Add' type=Add>,\n",
       " <tf.Operation 'Placeholder' type=Placeholder>,\n",
       " <tf.Operation 'Variable/Initializer/initial_value' type=Const>,\n",
       " <tf.Operation 'Variable' type=VarHandleOp>,\n",
       " <tf.Operation 'Variable/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>,\n",
       " <tf.Operation 'Variable/Assign' type=AssignVariableOp>,\n",
       " <tf.Operation 'Variable/Read/ReadVariableOp' type=ReadVariableOp>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e= tf.compat.v1.Variable(2)\n",
    "graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Const\n",
      "Const_1\n",
      "Add\n",
      "Placeholder\n",
      "Variable/Initializer/initial_value\n",
      "Variable\n",
      "Variable/IsInitialized/VarIsInitializedOp\n",
      "Variable/Assign\n",
      "Variable/Read/ReadVariableOp\n"
     ]
    }
   ],
   "source": [
    "for operation in graph.get_operations() :\n",
    "    print(operation.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7- Eager Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor(25, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(b'aGVsbG8gd29ybGQ', shape=(), dtype=string)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.add(1, 2))\n",
    "print(tf.add([1, 2], [3, 4]))\n",
    "print(tf.square(5))\n",
    "print(tf.reduce_sum([1, 2, 3]))\n",
    "print(tf.compat.v1.encode_base64(\"hello world\"))\n",
    "\n",
    "print(tf.square(2) + tf.square(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.matmul([[1]], [[2, 3]])\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Define constant tensors\n",
      "a = 2\n",
      "b = 3\n"
     ]
    }
   ],
   "source": [
    "# Define constant tensors\n",
    "print(\"Define constant tensors\")\n",
    "a = tf.constant(2)\n",
    "print(\"a = %i\" % a)\n",
    "b = tf.constant(3)\n",
    "print(\"b = %i\" % b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running operations, without tf.Session\n",
      "a + b = 5\n",
      "a * b = 6\n",
      "Mixing operations with Tensors and Numpy Arrays\n"
     ]
    }
   ],
   "source": [
    "# Run the operation without the need for tf.Session\n",
    "print(\"Running operations, without tf.Session\")\n",
    "c = a + b\n",
    "print(\"a + b = %i\" % c)\n",
    "d = a * b\n",
    "print(\"a * b = %i\" % d)\n",
    "\n",
    "# Full compatibility with Numpy\n",
    "print(\"Mixing operations with Tensors and Numpy Arrays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:\n",
      " a = tf.Tensor(\n",
      "[[2. 1.]\n",
      " [1. 0.]], shape=(2, 2), dtype=float32)\n",
      "NumpyArray:\n",
      " b = [[3. 0.]\n",
      " [5. 1.]]\n",
      "Running operations, without tf.Session\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Define constant tensors\n",
    "a = tf.constant([[2., 1.],\n",
    "                 [1., 0.]], dtype=tf.float32)\n",
    "print(\"Tensor:\\n a = %s\" % a)\n",
    "b = np.array([[3., 0.],\n",
    "              [5., 1.]], dtype=np.float32)\n",
    "print(\"NumpyArray:\\n b = %s\" % b)\n",
    "\n",
    "# Run the operation without the need for tf.Session\n",
    "print(\"Running operations, without tf.Session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a + b = tf.Tensor(\n",
      "[[5. 1.]\n",
      " [6. 1.]], shape=(2, 2), dtype=float32)\n",
      "a * b = tf.Tensor(\n",
      "[[11.  1.]\n",
      " [ 3.  0.]], shape=(2, 2), dtype=float32)\n",
      "Iterate through Tensor 'a':\n",
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c = a + b\n",
    "print(\"a + b = %s\" % c)\n",
    "\n",
    "d = tf.matmul(a, b)\n",
    "print(\"a * b = %s\" % d)\n",
    "\n",
    "print(\"Iterate through Tensor 'a':\")\n",
    "for i in range(a.shape[0]):\n",
    "    for j in range(a.shape[1]):\n",
    "        print(a[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
